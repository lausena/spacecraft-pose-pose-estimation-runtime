{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7592438-e787-4909-86c5-9299751cdcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transforms3d --quiet\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import transforms3d.quaternions as quat\n",
    "from scipy import signal\n",
    "import scipy.fft as sfft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "011ea9ab-a93a-45b9-aeda-23809410a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_length_x = 5212.5371\n",
    "focal_length_y = 6255.0444\n",
    "principal_point_x = 640.\n",
    "principal_point_y = 512.\n",
    "K = np.array([[focal_length_x, 0, principal_point_x],\n",
    "                          [0, focal_length_y,principal_point_y],\n",
    "                          [0, 0, 1]])\n",
    "P = np.array([[focal_length_x, 0, principal_point_x, 0],\n",
    "                          [0, focal_length_y,principal_point_y, 0],\n",
    "                          [0, 0, 1, 0]])\n",
    "\n",
    "laser_range_distance = 300\n",
    "\n",
    "labels = np.array([[7.64022827,-46.98920059,-42.21747971,0.98997474,-0.0941886,-0.07856753,0.07003857],\n",
    "    [12.37142944,-36.08272934,-76.19368744,0.98547542,-0.09323603,-0.13402745,0.04670797],\n",
    "    [48.83045959,-62.45590591,-149.01345825,0.9463315,-0.15760925,-0.27446723,0.06544811],\n",
    "    [42.9213562,3.1468811,-156.43341064,0.96294099,-0.05801675,-0.26296937,-0.0150205],\n",
    "    [25.3291626,-15.59156799,-118.26628113,0.97709697,-0.05717814,-0.20439324,0.01534067],\n",
    "    [55.51976013,-30.00940132,-172.91856384,0.94631386,-0.10770535,-0.30420068,0.01874543],\n",
    "    [ 69.65390015,-14.23764992,-194.42814636,0.93474096,-0.0921587,-0.34309945,-0.00697307],\n",
    "    [67.03590393,57.95062637,-181.86766052,0.94076264,0.03300816,-0.32461578,-0.09219801],\n",
    "    [95.08578491,70.74472046,-209.08718872,0.91551983,0.02235752,-0.38302255,-0.12090118],\n",
    "    [115.60142517,80.90587616,-223.3885498,0.89717531,0.01968047,-0.41800421,-0.14128494]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecaefb9d-93da-4281-a63c-3a44c2af2e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/lausena/developer/repos/spacecraft-pose-pose-estimation-runtime/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1e9ca88-ae5a-4220-ae43-1846e3fb1409",
   "metadata": {},
   "outputs": [],
   "source": [
    "orb = cv2.ORB_create(10000)\n",
    "FLANN_INDEX_LSH = 6\n",
    "index_params = dict(algorithm=FLANN_INDEX_LSH, table_number=6, key_size=12, multi_probe_level=1)\n",
    "search_params = dict(checks=50)\n",
    "flann = cv2.FlannBasedMatcher(indexParams=index_params, searchParams=search_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86d502aa-1f19-4a5b-a036-a0655ce0a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1path = os.path.join(root, 'data/images/01f0f7459b/000.png')\n",
    "img2path = os.path.join(root, 'data/images/01f0f7459b/001.png')\n",
    "\n",
    "img1 = cv2.imread(img1path, cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread(img2path, cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "034ebc03-c377-47e3-8be0-d4cde9738b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints1, descriptors1 = orb.detectAndCompute(img1, None)\n",
    "keypoints2, descriptors2 = orb.detectAndCompute(img2, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef10d729-489e-4dee-b762-2b5d690af4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = flann.knnMatch(descriptors1, descriptors2, k=2)\n",
    "good = []\n",
    "for match_pair in matches:\n",
    "    if len(match_pair) < 2:\n",
    "        continue  # Skip this match pair if it doesn't have two elements\n",
    "    m, n = match_pair\n",
    "    if m.distance < 0.8 * n.distance:\n",
    "        good.append(m)\n",
    "\n",
    "len(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd63ace5-8a98-457b-a438-97f73651b3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.DMatch 0x7fb75f7f3470>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "614c4ee5-c215-44aa-9177-807c1ba5aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = np.float32([keypoints1[m.queryIdx].pt for m in good])\n",
    "q2 = np.float32([keypoints2[m.queryIdx].pt for m in good])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11ecebae-4ae1-4326-a067-f50bbc808ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "green = (0, 255, 0)\n",
    "draw_params = dict(\n",
    "    matchColor=green, # draw matches in green\n",
    "    singlePointColor=None,\n",
    "    matchesMask=None, # only draw inliers\n",
    "    flags=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63e466c5-c9e9-44b2-8b62-125555743505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img3 = cv2.drawMatches(img1, keypoints1, img2, keypoints2, good, None, **draw_params)\n",
    "# cv2.imshow(\"image\", img3)\n",
    "# cv2.waitKey(0)\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63a222f5-bda7-4dad-ba42-6de21a15702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Essential, mask = cv2.findEssentialMat(q1, q2, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e02f92a7-1bd4-49d8-aca1-c1ee788f19e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_transf(R, t):\n",
    "        \"\"\"\n",
    "        Makes a transformation matrix from the given rotation matrix and translation vector\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        R (ndarray): The rotation matrix\n",
    "        t (list): The translation vector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        T (ndarray): The transformation matrix\n",
    "        \"\"\"\n",
    "        T = np.eye(4, dtype=np.float64)\n",
    "        T[:3, :3] = R\n",
    "        T[:3, 3] = t\n",
    "        return T\n",
    "\n",
    "def decomp_essential_mat(E, q1, q2):\n",
    "        \"\"\"\n",
    "        Decompose the Essential matrix\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        E (ndarray): Essential matrix\n",
    "        q1 (ndarray): The good keypoints matches position in i-1'th image\n",
    "        q2 (ndarray): The good keypoints matches position in i'th image\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        right_pair (list): Contains the rotation matrix and translation vector\n",
    "        \"\"\"\n",
    "        def sum_z_cal_relative_scale(R, t):\n",
    "            # Get the transformation matrix\n",
    "            T = form_transf(R, t)\n",
    "            # Make the projection matrix\n",
    "            P_cur = np.matmul(np.concatenate((K, np.zeros((3, 1))), axis=1), T)\n",
    "\n",
    "            # Triangulate the 3D points\n",
    "            hom_Q1 = cv2.triangulatePoints(P, P_cur, q1.T, q2.T)\n",
    "            # Also seen from cam 2\n",
    "            hom_Q2 = np.matmul(T, hom_Q1)\n",
    "\n",
    "            # Un-homogenize\n",
    "            uhom_Q1 = hom_Q1[:3, :] / hom_Q1[3, :]\n",
    "            uhom_Q2 = hom_Q2[:3, :] / hom_Q2[3, :]\n",
    "\n",
    "            # Find the number of points there has positive z coordinate in both cameras\n",
    "            sum_of_pos_z_Q1 = sum(uhom_Q1[2, :] > 0)\n",
    "            sum_of_pos_z_Q2 = sum(uhom_Q2[2, :] > 0)\n",
    "\n",
    "            # Form point pairs and calculate the relative scale\n",
    "            relative_scale = np.mean(np.linalg.norm(uhom_Q1.T[:-1] - uhom_Q1.T[1:], axis=-1)/\n",
    "                                     np.linalg.norm(uhom_Q2.T[:-1] - uhom_Q2.T[1:], axis=-1))\n",
    "            return sum_of_pos_z_Q1 + sum_of_pos_z_Q2, relative_scale\n",
    "\n",
    "        # Decompose the essential matrix\n",
    "        R1, R2, t = cv2.decomposeEssentialMat(E)\n",
    "        t = np.squeeze(t)\n",
    "\n",
    "        # Make a list of the different possible pairs\n",
    "        pairs = [[R1, t], [R1, -t], [R2, t], [R2, -t]]\n",
    "\n",
    "        # Check which solution there is the right one\n",
    "        z_sums = []\n",
    "        relative_scales = []\n",
    "        for R, t in pairs:\n",
    "            z_sum, scale = sum_z_cal_relative_scale(R, t)\n",
    "            z_sums.append(z_sum)\n",
    "            relative_scales.append(scale)\n",
    "\n",
    "        # Select the pair there has the most points with positive z coordinate\n",
    "        right_pair_idx = np.argmax(z_sums)\n",
    "        right_pair = pairs[right_pair_idx]\n",
    "        relative_scale = relative_scales[right_pair_idx]\n",
    "        R1, t = right_pair\n",
    "        print(relative_scale)\n",
    "        # t = t * relative_scale\n",
    "        t\n",
    "\n",
    "        return [R1, t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0af859fe-45f4-4ad3-91e4-f65cf2c0b8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "R1, R2, t = cv2.decomposeEssentialMat(Essential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dde0f2b8-1142-429e-8725-27104450920e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999998344473872\n"
     ]
    }
   ],
   "source": [
    "rotation, transformation = decomp_essential_mat(Essential, q1, q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b7a0ba3-c9a3-4b78-bf45-f78287372b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.64022827, -46.98920059, -42.21747971])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_trans = labels[0][:3]\n",
    "original_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "116e39c5-3e14-43f6-8ea3-1e4176497dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00774799,  0.0090509 ,  0.99992902])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df9c943e-41d8-409f-8580-c3e7cb43035b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.94339355073174"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(original_trans, t.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3771335-4185-4073-bfde-516dfbe63417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17873354,  0.98292291,  0.04378225, -0.00774799],\n",
       "       [ 0.98290868, -0.1763825 , -0.0527232 ,  0.0090509 ],\n",
       "       [-0.04410042,  0.05245736, -0.99764893,  0.99992902],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# T = np.eye(4, dtype=np.float64)\n",
    "# T[:3, :3] = rotation\n",
    "# T[:3, 3] = transformation\n",
    "# T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f0fe8a-3ae6-4017-ae5b-c64ada4256e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
