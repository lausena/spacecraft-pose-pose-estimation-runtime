{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95276a61-386d-4ebb-9ce4-f64a5e070b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lausena/developer/repos/spacecraft-pose-pose-estimation-runtime/juptyer-notebooks\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db1aad66-1ae3-4fff-b703-b5312023d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transforms3d --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b25795b-5f49-4e90-aa8a-3cb69b3bd5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import transforms3d.quaternions as quat\n",
    "from scipy import signal\n",
    "import scipy.fft as sfft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98ca6485-6b16-4a0e-8f39-2d5522d8bd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_matrix = np.array([[5.2125371e+03, 0.0000000e+00, 6.4000000e+02],\n",
    "                          [0.0000000e+00, 6.2550444e+03, 5.1200000e+02],\n",
    "                          [0.0000000e+00, 0.0000000e+00, 1.0000000e+00]])\n",
    "\n",
    "# range 01f0f7459b,0,299.2\n",
    "#01f0f7459b,1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8214af42-fbe0-4b14-a782-5b01b5ce8f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/lausena/developer/repos/spacecraft-pose-pose-estimation-runtime/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "97723957-4150-4db7-a8e1-25e030940a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image 001:\n",
    "# trans 7.64022827,-46.98920059,-42.21747971\n",
    "# quat ,0.98997474,-0.0941886,-0.07856753,0.07003857\n",
    "orig_trans = np.array([7.64022827,-46.98920059,-42.21747971])\n",
    "orig_quat = np.array([0.98997474,-0.0941886,-0.07856753,0.07003857])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d64db779-0047-4d80-b0c8-b479da2ff25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_test(img1, img2, orig_trans, orig_quat):\n",
    "    orb = cv2.ORB_create()\n",
    "    kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "    kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "    # Match keypoints\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    # Extract matched keypoints\n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "    # Estimate homography\n",
    "    # H, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC)\n",
    "    H, _ = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC)\n",
    "\n",
    "    num, Rs, Ts, Ns = cv2.decomposeHomographyMat(H, camera_matrix)\n",
    "    a = Rotation.from_matrix(Rs[0]).as_quat()\n",
    "    b = Rotation.from_matrix(H).as_quat()\n",
    "\n",
    "    # print('Quaternion test:')\n",
    "    # print(f'{mean_absolute_error(a, orig_quat)} : Decomposition')\n",
    "    # print(mean_absolute_error(b, orig_quat))\n",
    "    # print()\n",
    "    print('Translation test:')\n",
    "    print(f'{mean_absolute_error(np.array([0.,0.,0.]), orig_trans)} Base case')\n",
    "    print(mean_absolute_error(Ts[0], orig_trans))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6c33e810-19c6-460a-8264-dc006efa1ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image = 1\n",
      "Translation test:\n",
      "32.28230285666667 Base case\n",
      "33.59082343862354\n",
      "\n",
      "Image = 2\n",
      "Translation test:\n",
      "41.54928207333334 Base case\n",
      "45.747369978317465\n",
      "\n",
      "Image = 3\n",
      "Translation test:\n",
      "86.76660791666666 Base case\n",
      "91.3611142404352\n",
      "\n",
      "Image = 4\n",
      "Translation test:\n",
      "67.50054931333334 Base case\n",
      "53.65835905079221\n",
      "\n",
      "Image = 5\n",
      "Translation test:\n",
      "53.06233724 Base case\n",
      "57.6353925224469\n",
      "\n",
      "Image = 6\n",
      "Translation test:\n",
      "86.14924176333334 Base case\n",
      "39.95098152651341\n",
      "\n",
      "Image = 7\n",
      "Translation test:\n",
      "92.77323214333335 Base case\n",
      "39.434431765392404\n",
      "\n",
      "Image = 8\n",
      "Translation test:\n",
      "102.28473027333332 Base case\n",
      "57.15854380839394\n",
      "\n",
      "Image = 9\n",
      "Translation test:\n",
      "124.97256469666667 Base case\n",
      "89.59045605843141\n",
      "\n",
      "Image = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@2219.469] global loadsave.cpp:248 findDecoder imread_('/home/lausena/developer/repos/spacecraft-pose-pose-estimation-runtime/data/images/01f0f7459b/0010.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@2219.497] global loadsave.cpp:248 findDecoder imread_('/home/lausena/developer/repos/spacecraft-pose-pose-estimation-runtime/data/images/01f0f7459b/0010.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) /home/conda/feedstock_root/build_artifacts/libopencv_1704864625327/work/modules/core/src/batch_distance.cpp:274: error: (-215:Assertion failed) type == src2.type() && src1.cols == src2.cols && (type == CV_32F || type == CV_8U) in function 'batchDistance'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m original_trans \u001b[38;5;241m=\u001b[39m labels[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][:\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m     23\u001b[0m original_quat \u001b[38;5;241m=\u001b[39m labels[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m3\u001b[39m:]\n\u001b[0;32m---> 25\u001b[0m \u001b[43mexecute_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_trans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_quat\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[121], line 7\u001b[0m, in \u001b[0;36mexecute_test\u001b[0;34m(img1, img2, orig_trans, orig_quat)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Match keypoints\u001b[39;00m\n\u001b[1;32m      6\u001b[0m bf \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mBFMatcher(cv2\u001b[38;5;241m.\u001b[39mNORM_HAMMING, crossCheck\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 7\u001b[0m matches \u001b[38;5;241m=\u001b[39m \u001b[43mbf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdes1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdes2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Extract matched keypoints\u001b[39;00m\n\u001b[1;32m      9\u001b[0m src_pts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32([kp1[m\u001b[38;5;241m.\u001b[39mqueryIdx]\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m matches])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /home/conda/feedstock_root/build_artifacts/libopencv_1704864625327/work/modules/core/src/batch_distance.cpp:274: error: (-215:Assertion failed) type == src2.type() && src1.cols == src2.cols && (type == CV_32F || type == CV_8U) in function 'batchDistance'\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    print(f'Image = {i}')\n",
    "    img1path = os.path.join(root, 'data/images/01f0f7459b/000.png')\n",
    "    img2path = os.path.join(root, f'data/images/01f0f7459b/00{i}.png')\n",
    "    \n",
    "    img1 = cv2.imread(img1path, cv.IMREAD_GRAYSCALE)\n",
    "    img2 = cv2.imread(img2path, cv.IMREAD_GRAYSCALE)\n",
    "    img1full = cv2.imread(img1path, cv.IMREAD_GRAYSCALE)\n",
    "    img2full = cv2.imread(img2path, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "    labels = np.array([[7.64022827,-46.98920059,-42.21747971,0.98997474,-0.0941886,-0.07856753,0.07003857],\n",
    "        [12.37142944,-36.08272934,-76.19368744,0.98547542,-0.09323603,-0.13402745,0.04670797],\n",
    "        [48.83045959,-62.45590591,-149.01345825,0.9463315,-0.15760925,-0.27446723,0.06544811],\n",
    "        [42.9213562,3.1468811,-156.43341064,0.96294099,-0.05801675,-0.26296937,-0.0150205],\n",
    "        [25.3291626,-15.59156799,-118.26628113,0.97709697,-0.05717814,-0.20439324,0.01534067],\n",
    "        [55.51976013,-30.00940132,-172.91856384,0.94631386,-0.10770535,-0.30420068,0.01874543],\n",
    "        [ 69.65390015,-14.23764992,-194.42814636,0.93474096,-0.0921587,-0.34309945,-0.00697307],\n",
    "        [67.03590393,57.95062637,-181.86766052,0.94076264,0.03300816,-0.32461578,-0.09219801],\n",
    "        [95.08578491,70.74472046,-209.08718872,0.91551983,0.02235752,-0.38302255,-0.12090118],\n",
    "        [115.60142517,80.90587616,-223.3885498,0.89717531,0.01968047,-0.41800421,-0.14128494]])\n",
    "\n",
    "    original_trans = labels[i-1][:3]\n",
    "    original_quat = labels[i-1][3:]\n",
    "    \n",
    "    execute_test(img1, img2, original_trans, original_quat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1c54ee-b495-4626-a792-7ac05c6e994e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9d8b4c-0b9e-48bd-9287-4a5c89bc448b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f77a5c-304a-4cb3-99f0-5fd24b65b644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fed9b07-5736-4190-8ec4-d5ee7cb61867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4977d283-f071-4b62-bf44-f7a740a57e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6b885852-96f8-4216-84d7-fe1f889dc4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints1, descriptor1 = sift.detectAndCompute(img1, None)\n",
    "keypoints2, descriptor2 = sift.detectAndCompute(img2, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "868852a8-e5e1-43de-a6c7-fb2c5833d433",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLANN_INDEX_KDTREE = 1\n",
    "indexParams = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "searchParams = dict(checks=50)\n",
    "flann = cv.FlannBasedMatcher(indexParams, searchParams)\n",
    "nNeighbors = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "03a56fcb-9ae9-402a-ac62-c321e5a636f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = flann.knnMatch(descriptor1, descriptor2, k=nNeighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9c9838db-6474-4aa4-84fe-f3872303dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "goodMatches = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.7*n.distance:\n",
    "        goodMatches.append(m)\n",
    "\n",
    "minGoodMatches = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "228465f3-f058-4a84-821b-27e0fd8f9f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(goodMatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2fb7f795-df62-40c5-88ff-d166d6b5a432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough good matches\n"
     ]
    }
   ],
   "source": [
    "if len(goodMatches) > minGoodMatches:\n",
    "    source_points = np.float32([keypoints1[m.queryIdx].pt for m in goodMatches]).reshape(-1,1,2)\n",
    "    destination_points = np.float32([keypoints2[m.queryIdx].pt for m in goodMatches]).reshape(-1,1,2)\n",
    "    errorThreshold = 5\n",
    "    M, mask = cv.findHomography(source_points, destination_points, cv.RANSAC, errorThreshold)\n",
    "    matches_mask = mask.ravel().tolist()\n",
    "    h,w = img1.shape\n",
    "    img_border = np.float32([[0,0], [0, h-1], [w-1, h-1], [w-1,0]]).reshape(-1,1,2)\n",
    "    warped_img_border = cv.perspectiveTransform(img_border, M)\n",
    "    img2_poly = cv.polylines(img2, [np.int32(warped_img_border)], True, 255, 3, cv.LINE_AA)\n",
    "else:\n",
    "    print('Not enough good matches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2dbaeced-ca99-40a5-b3c4-58c528ac3737",
   "metadata": {},
   "outputs": [],
   "source": [
    "num, Rs, Ts, Ns = cv2.decomposeHomographyMat(M, camera_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f66267eb-b6a0-4043-ab2d-23ceb12a9f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Rotation.from_matrix(Rs[0]).as_quat()\n",
    "b = Rotation.from_matrix(H).as_quat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "31e7de2d-2979-44bb-8b2a-840266a3cf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5360092775186155\n",
      "0.30566994567587386\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(a, orig_quat))\n",
    "print(mean_absolute_error(b, orig_quat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8900a0d2-6ecc-47d5-a5f8-b9b640a441b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.28230285666667\n",
      "1088.50286222482\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(np.array([0.,0.,0.]), orig_trans))\n",
    "print(mean_absolute_error(Ts[0], orig_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98491c65-91f1-44bc-b121-d1138d666060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cf3007-3dd9-471a-a427-de4ddf7d0d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
