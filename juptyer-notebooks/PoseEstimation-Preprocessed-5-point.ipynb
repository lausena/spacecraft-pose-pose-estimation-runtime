{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95276a61-386d-4ebb-9ce4-f64a5e070b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/m/Documents/DNN Final Project/spacecraft-pose-pose-estimation-runtime/juptyer-notebooks\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b25795b-5f49-4e90-aa8a-3cb69b3bd5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 14:25:42.251322: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-26 14:25:42.251399: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-26 14:25:42.252621: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-26 14:25:42.260550: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-26 14:25:43.899445: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D, Concatenate, Flatten, Conv2D, MaxPooling2D, AvgPool2D, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras import Model\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4705b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfY = pd.read_csv(\"../data/train_labels.csv\")[:1500]\n",
    "dfY[\"path\"] = [f\"../data/images/{id}/{i:03d}.png\" for id, i in zip(dfY[\"chain_id\"], dfY[\"i\"])]\n",
    "dfY[\"base_path\"] = [f\"../data/images/{id}/000.png\" for id, i in zip(dfY[\"chain_id\"], dfY[\"i\"])]\n",
    "x_train, x_test, y_train, y_test = train_test_split(dfY[[\"path\", \"base_path\"]], dfY[[\"x\", \"y\", \"z\", \"qw\",\"qx\",\"qy\",\"qz\"]], test_size=0.25, random_state=42)\n",
    "x_train = pd.DataFrame(x_train, columns=[\"path\", \"base_path\"])\n",
    "x_test = pd.DataFrame(x_test, columns=[\"path\", \"base_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "431fd5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pos.save('../models/test_model-logcosh-16x3-3e-00001-larger-kernels-11250.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c49f034",
   "metadata": {},
   "outputs": [],
   "source": [
    "ToCSV = lambda df, fname: df.round(2).to_csv(f'{fname}.csv')\n",
    "\n",
    "# Loads all images found and trains given model\n",
    "def load_images_and_train_model(model, is_pos_model):\n",
    "    with tf.device('/GPU:0'):\n",
    "        model.summary()\n",
    "        \n",
    "        #for i in range(batches):\n",
    "            #batch = load_new_batch()\n",
    "            #model.fit([np.asarray(batch[0]), np.asarray(batch[1])], y_train[100 * i : 100*(i+1)], epochs=40, batch_size=batch_size_b)\n",
    "        if is_pos_model:\n",
    "            ypos = pd.DataFrame(y_train, index=y_train.index, columns=[\"x\", \"y\", \"z\"])\n",
    "            model.fit(CustomDataGenerator(x_train, y_train, batch_size=100), epochs=3)\n",
    "        else:\n",
    "            yquat = pd.DataFrame(y_train, index=y_train.index, columns=[\"qw\", \"qx\", \"qy\", \"qz\"])\n",
    "            model.fit(CustomDataGenerator(x_train, yquat, batch_size=100), epochs=3)\n",
    "\n",
    "\n",
    "        \n",
    "    #     ypreddf = pd.DataFrame(ypred.T, index=image_label_ds.take(count * 100 * 0.2).index_array, columns=[\"x\", \"y\", \"z\"])\n",
    "    #     dfY = pd.read_csv(\"../data/train_labels.csv\")[:count * 100]\n",
    "    #     dfY_merged = pd.merge(ypreddf.drop([\"x\", \"y\", \"z\"], axis=1), dfY, left_index=True, right_index=True)\n",
    "    #     dfYidx = dfY.drop([\"x\", \"y\", \"z\", \"qw\", \"qx\", \"qy\", \"qz\"], axis=1)\n",
    "    #     df_merged = pd.merge(ypreddf, dfYidx, left_index=True, right_index=True)\n",
    "    #     df_merged[\"qw\"] = 0\n",
    "    #     df_merged[\"qx\"] = 0\n",
    "    #     df_merged[\"qy\"] = 0\n",
    "    #     df_merged[\"qz\"] = 0\n",
    "    #     df_merged.loc[df_merged[\"i\"] == 0, [\"x\", \"y\", \"z\", \"qw\", \"qx\", \"qy\", \"qz\"]] = [0,0,0,1,0,0,0]\n",
    "    #     df_merged.set_index([\"chain_id\", \"i\"], inplace=True)\n",
    "    #    # df_merged.drop([\"id\"], axis=1, inplace=True)\n",
    "    #     ToCSV(df_merged, \"cnn-test\")\n",
    "    #     ToCSV(dfY_merged, \"cnn-true\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# from https://github.com/1988kramer/camera-pose/blob/master/camera-pose.py \n",
    "def create_conv_branch(input_shape):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(96, kernel_size=(11,11),\n",
    "\t\t\t\t\t strides=4, padding='valid',\n",
    "\t\t\t\t\t activation='relu',\n",
    "\t\t\t\t\t input_shape=input_shape))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\t# model.add(Conv2D(128, kernel_size=(5,5),\n",
    "\t# \t\t\t\t strides=1, padding='same',\n",
    "\t# \t\t\t\t activation='relu'))\n",
    "\t# model.add(MaxPooling2D(pool_size=(3,3), strides=1))\n",
    "\t# model.add(Conv2D(256, kernel_size=(3,3),\n",
    "\t# \t\t\t\t strides=1, padding='same',\n",
    "\t# \t\t\t\t activation='relu'))\n",
    "\t# model.add(Conv2D(256, kernel_size=(3,3),\n",
    "\t# \t\t\t\t strides=1, padding='same',\n",
    "\t# \t\t\t\t activation='relu'))\n",
    "\t# model.add(Conv2D(128, kernel_size=(3,3),\n",
    "\t# \t\t\t\t strides=1, padding='same',\n",
    "\t# \t\t\t\t activation='relu'))\n",
    "\t# model.add(MaxPooling2D(pool_size=(3,3), strides=2))\n",
    "\t# model.add(Conv2D(256, kernel_size=(3,3),\n",
    "\t# \t\t\t\t strides=1, padding='same',\n",
    "\t# \t\t\t\t activation='relu'))\n",
    "\t# model.add(Conv2D(128, kernel_size=(3,3),\n",
    "\t# \t\t\t\t strides=1, padding='same',\n",
    "\t# \t\t\t\t activation='relu'))\n",
    "\treturn model\n",
    "\n",
    "def create_conv_branch_pos(input_shape):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(96, kernel_size=(11,11),\n",
    "\t\t\t\t\t strides=4, padding='valid',\n",
    "\t\t\t\t\t activation='relu',\n",
    "\t\t\t\t\t input_shape=input_shape))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\tmodel.add(Conv2D(128, kernel_size=(7,7),\n",
    "\t\t\t\t\t strides=1, padding='same',\n",
    "\t\t\t\t\t activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(3,3), strides=1))\n",
    "\tmodel.add(Conv2D(256, kernel_size=(5,5),\n",
    "\t\t\t\t\t strides=1, padding='same',\n",
    "\t\t\t\t\t activation='relu'))\n",
    "\tmodel.add(Conv2D(256, kernel_size=(3,3),\n",
    "\t\t\t\t\t strides=1, padding='same',\n",
    "\t\t\t\t\t activation='relu'))\n",
    "\tmodel.add(Conv2D(128, kernel_size=(3,3),\n",
    "\t\t\t\t\t strides=1, padding='same',\n",
    "\t\t\t\t\t activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(3,3), strides=2))\n",
    "\tmodel.add(Conv2D(256, kernel_size=(5,5),\n",
    "\t\t\t\t\t strides=1, padding='same',\n",
    "\t\t\t\t\t activation='relu'))\n",
    "\tmodel.add(Conv2D(128, kernel_size=(3,3),\n",
    "\t\t\t\t\t strides=1, padding='same',\n",
    "\t\t\t\t\t activation='relu'))\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98b8fff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/63827339/how-to-build-a-custom-data-generator-for-keras-tf-keras-where-x-images-are-being\n",
    "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
    "\n",
    "    ''' Custom DataGenerator to load img \n",
    "    \n",
    "    Arguments:\n",
    "        data_frame = pandas data frame in filenames and labels format\n",
    "        batch_size = divide data in batches\n",
    "        shuffle = shuffle data before loading\n",
    "        img_shape = image shape in (h, w, d) format\n",
    "        augmentation = data augmentation to make model rebust to overfitting\n",
    "    \n",
    "    Output:\n",
    "        Img: numpy array of image\n",
    "        label : output label for image\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, data_frame, labels, batch_size=10, img_shape=None, augmentation=True, num_classes=None):\n",
    "        self.data_frame = data_frame\n",
    "        self.labels = labels\n",
    "        self.train_len = len(data_frame)\n",
    "        self.batch_size = batch_size\n",
    "        self.img_shape = img_shape\n",
    "        self.num_classes = num_classes\n",
    "        print(f\"Found {self.data_frame.shape[0]} images belonging to {self.num_classes} classes\")\n",
    "\n",
    "    def __len__(self):\n",
    "        ''' return total number of batches '''\n",
    "        #self.data_frame = shuffle(self.data_frame)\n",
    "        return math.ceil(self.train_len/self.batch_size)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        ''' shuffle data after every epoch '''\n",
    "        # fix on epoch end it's not working, adding shuffle in len for alternative\n",
    "        pass\n",
    "    \n",
    "    def __data_augmentation(self, img):\n",
    "        ''' function for apply some data augmentation '''\n",
    "        img = tf.image.resize(img, 512, 640)\n",
    "        img = tf.image.random_flip_up_down(img)\n",
    "        return img\n",
    "        \n",
    "    def __get_image(self, file_id):\n",
    "        \"\"\" open image with file_id path and apply data augmentation \"\"\"\n",
    "        img = np.asarray(Image.open(file_id))\n",
    "        img = np.resize(img, self.img_shape)\n",
    "        img = self.__data_augmentation(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def __get_label(self, label_id):\n",
    "        \"\"\" uncomment the below line to convert label into categorical format \"\"\"\n",
    "        #label_id = tf.keras.utils.to_categorical(label_id, num_classes)\n",
    "        return label_id\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # batch_x = self.data_frame[\"filenames\"][idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        # batch_y = self.data_frame[\"labels\"][idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        # # read your data here using the batch lists, batch_x and batch_y\n",
    "        # x = [self.__get_image(file_id) for file_id in batch_x] \n",
    "        # y = [self.__get_label(label_id) for label_id in batch_y]\n",
    "\n",
    "        y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        paths = self.data_frame[\"path\"][idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        base_paths = self.data_frame[\"base_path\"][idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        #raw = [tf.io.read_file(path) for path in paths]\n",
    "        image = [tf.image.resize(tf.image.decode_png(tf.io.read_file(path), channels=3), (512,640)) for path in paths]\n",
    "        #base_raw = tf.io.read_file(base_path)\n",
    "        base_image = [tf.image.resize(tf.image.decode_png(tf.io.read_file(path), channels=3), (512,640)) for path in base_paths]\n",
    "\n",
    "        return [np.asarray(base_image), np.asarray(image)], y\n",
    "\n",
    "        #return tf.convert_to_tensor(x), tf.convert_to_tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f054cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeQuat(x: tf.Tensor):\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(x)))\n",
    "    x = x / norm\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fae3acaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 14:25:48.065277: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 512, 640, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 512, 640, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " sequential (Sequential)     (None, 63, 79, 96)           34944     ['input_1[0][0]',             \n",
      "                                                                     'input_2[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 63, 79, 192)          0         ['sequential[0][0]',          \n",
      "                                                                     'sequential[1][0]']          \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 955584)               0         ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 955584)               0         ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 8)                    7644680   ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 4)                    36        ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " lambda (Lambda)             (None, 4)                    0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7679660 (29.30 MB)\n",
      "Trainable params: 7679660 (29.30 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 512, 640, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 512, 640, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " sequential (Sequential)     (None, 63, 79, 96)           34944     ['input_1[0][0]',             \n",
      "                                                                     'input_2[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 63, 79, 192)          0         ['sequential[0][0]',          \n",
      "                                                                     'sequential[1][0]']          \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 955584)               0         ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 955584)               0         ['flatten[0][0]']             \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 14:25:48.116039: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-26 14:25:48.116350: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-26 14:25:48.119127: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-26 14:25:48.119603: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-26 14:25:48.119970: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-26 14:25:48.334212: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-26 14:25:48.334511: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-26 14:25:48.334527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-26 14:25:48.334794: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-26 14:25:48.334822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9702 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense (Dense)               (None, 8)                    7644680   ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 4)                    36        ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " lambda (Lambda)             (None, 4)                    0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7679660 (29.30 MB)\n",
      "Trainable params: 7679660 (29.30 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Found 1125 images belonging to None classes\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 14:26:04.852455: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-04-26 14:26:05.103480: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-26 14:26:18.271820: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-26 14:26:19.085030: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f5dcc55ca60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-26 14:26:19.085086: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2024-04-26 14:26:19.092039: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1714159579.178895   25857 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 105s 7s/step - loss: 0.3938\n",
      "Epoch 2/3\n",
      "12/12 [==============================] - 84s 7s/step - loss: 0.3880\n",
      "Epoch 3/3\n",
      "12/12 [==============================] - 90s 8s/step - loss: 0.3825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x7f5eb80dfac0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_shape=(512, 640, 3)\n",
    "\n",
    "# Rotation model\n",
    "conv_branch = create_conv_branch(input_shape)\n",
    "branch_a = Input(shape=input_shape)\n",
    "branch_b = Input(shape=input_shape)\n",
    "\n",
    "processed_a = conv_branch(branch_a)\n",
    "processed_b = conv_branch(branch_b)\n",
    "\n",
    "concat = keras.layers.concatenate([processed_a, processed_b])\n",
    "x1 = Flatten()(concat)\n",
    "x1 = Dropout(0.25)(x1)\n",
    "x1 = Dense(8)(x1)\n",
    "output = Dense(4)(x1)\n",
    "postprocess = Lambda(NormalizeQuat, output_shape=(None,4))(output)\n",
    "\n",
    "model_rot = Model(inputs=[branch_a,branch_b], outputs=postprocess)\n",
    "model_rot.compile(optimizer=Adam(learning_rate=0.001), loss=\"mae\")\n",
    "model_rot.summary()\n",
    "load_images_and_train_model(model_rot, False)\n",
    "\n",
    "# Position model\n",
    "# conv_branch = create_conv_branch_pos(input_shape)\n",
    "# branch_a = Input(shape=input_shape)\n",
    "# branch_b = Input(shape=input_shape)\n",
    "\n",
    "# processed_a = conv_branch(branch_a)\n",
    "# processed_b = conv_branch(branch_b)\n",
    "\n",
    "# concat = keras.layers.concatenate([processed_a, processed_b])\n",
    "\n",
    "# x1 = Flatten()(concat)\n",
    "# x1 = Dropout(0.25)(x1)\n",
    "# x1 = Dense(16)(x1)\n",
    "# x1 = Dropout(0.25)(x1)\n",
    "# x1 = Dense(16)(x1)\n",
    "# x1 = Dropout(0.25)(x1)\n",
    "# x1 = Dense(16)(x1)\n",
    "# output = Dense(7)(x1)\n",
    "\n",
    "# model_pos = Model(inputs=[branch_a,branch_b], outputs=output)\n",
    "# model_pos.compile(optimizer=Adam(learning_rate=0.0001), loss=\"log_cosh\")\n",
    "# model_pos.summary()\n",
    "# load_images_and_train_model(model_pos, True)\n",
    "\n",
    "# yhat = model(x_test)\n",
    "# var_inv = 1 / yhat.variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38166d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "ypred = pd.DataFrame(model_rot.predict(CustomDataGenerator(x_test, y_test, 20)), index=y_test.index, columns=[\"qw\", \"qx\", \"qy\", \"qz\"]) # Predict rotation\n",
    "#ypred = pd.DataFrame(model_pos.predict(CustomDataGenerator(x_test, y_test, 50)), index=y_test.index, columns=[\"x\", \"y\", \"z\", \"qw\", \"qx\", \"qy\", \"qz\"]) # Predict position\n",
    "#ypred = pd.merge(ypred_pos, ypred_rot, left_index=True, right_index=True)\n",
    "#ypred[[\"qw\", \"qx\", \"qy\", \"qz\"]] = ypred[[\"qw\", \"qx\", \"qy\", \"qz\"]].clip(lower=-1, upper=1)\n",
    "\n",
    "ypred[\"chain_id\"] = dfY.iloc[ypred.index].chain_id\n",
    "ypred[\"i\"] = dfY.iloc[ypred.index].i.astype(int)\n",
    "# y_pred_norm = np.linalg.norm(ypred[[\"qw\", \"qx\", \"qy\", \"qz\"]], axis=1)\n",
    "# ypred[\"qw\"] = ypred[\"qw\"] / y_pred_norm\n",
    "# ypred[\"qx\"] = ypred[\"qx\"] / y_pred_norm\n",
    "# ypred[\"qy\"] = ypred[\"qy\"] / y_pred_norm\n",
    "# ypred[\"qz\"] = ypred[\"qz\"] / y_pred_norm\n",
    "#ypred.loc[ypred.i == 0, [\"x\", \"y\", \"z\", \"qw\", \"qx\", \"qy\", \"qz\"]] = [0,0,0,1,0,0,0]\n",
    "# ypred[[\"qw\", \"qx\", \"qy\", \"qz\"]] = [0,0,0,0]\n",
    "ypred[[\"x\", \"y\", \"z\"]] = [0,0,0]\n",
    "ypred = ypred[[\"chain_id\", \"i\", \"x\", \"y\", \"z\", \"qw\", \"qx\", \"qy\", \"qz\"]]\n",
    "ypred.loc[ypred.i == 0, [\"x\", \"y\", \"z\", \"qw\", \"qx\", \"qy\", \"qz\"]] = [0,0,0,1,0,0,0]\n",
    "ypred.set_index([\"chain_id\", \"i\"], inplace=True)\n",
    "ToCSV(ypred, \"cnn-test\")\n",
    "y_copy = y_test.copy()\n",
    "y_copy[\"chain_id\"] = dfY.iloc[y_copy.index].chain_id\n",
    "y_copy[\"i\"] = dfY.iloc[y_copy.index].i.astype(int)\n",
    "y_copy.set_index([\"chain_id\", \"i\"], inplace=True)\n",
    "ToCSV(y_copy, \"cnn-true\")\n",
    "\n",
    "#model.save('../models/test_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
