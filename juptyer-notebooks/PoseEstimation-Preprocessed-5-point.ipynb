{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95276a61-386d-4ebb-9ce4-f64a5e070b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/m/Documents/DNN Final Project/spacecraft-pose-pose-estimation-runtime/juptyer-notebooks\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b25795b-5f49-4e90-aa8a-3cb69b3bd5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 22:58:27.201764: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-29 22:58:27.201894: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-29 22:58:27.292485: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-29 22:58:27.304571: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-29 22:58:29.050826: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D, Concatenate, Flatten, Conv2D, MaxPooling2D, AvgPool2D, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras import Model\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4705b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    path                          base_path  \\\n",
      "59425  ../data/images/e8bd0b6fd9/025.png  ../data/images/e8bd0b6fd9/000.png   \n",
      "25193  ../data/images/6397cf55d5/093.png  ../data/images/6397cf55d5/000.png   \n",
      "46927  ../data/images/b932d56657/027.png  ../data/images/b932d56657/000.png   \n",
      "64193  ../data/images/f7ca61cc93/093.png  ../data/images/f7ca61cc93/000.png   \n",
      "3437   ../data/images/0e90967346/037.png  ../data/images/0e90967346/000.png   \n",
      "...                                  ...                                ...   \n",
      "51345  ../data/images/cad338efca/045.png  ../data/images/cad338efca/000.png   \n",
      "12496  ../data/images/2db4b73861/096.png  ../data/images/2db4b73861/000.png   \n",
      "45569  ../data/images/b44cf93326/069.png  ../data/images/b44cf93326/000.png   \n",
      "34780  ../data/images/88b7f5fa26/080.png  ../data/images/88b7f5fa26/000.png   \n",
      "21564  ../data/images/542f53a194/064.png  ../data/images/542f53a194/000.png   \n",
      "\n",
      "       range  \n",
      "59425  386.4  \n",
      "25193  240.4  \n",
      "46927  409.7  \n",
      "64193  365.1  \n",
      "3437   390.2  \n",
      "...      ...  \n",
      "51345  236.2  \n",
      "12496  280.0  \n",
      "45569  178.8  \n",
      "34780  386.1  \n",
      "21564  336.9  \n",
      "\n",
      "[2500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "dfY = pd.read_csv(\"../data/train_labels.csv\")\n",
    "df_range = pd.read_csv(\"../data/range.csv\")\n",
    "df_range = df_range.ffill()\n",
    "dfY = pd.merge(dfY, df_range, left_on=['chain_id','i'], right_on=['chain_id','i'])\n",
    "dfY = dfY.sample(n=5000, random_state=42)\n",
    "dfY[\"path\"] = [f\"../data/images/{id}/{i:03d}.png\" for id, i in zip(dfY[\"chain_id\"], dfY[\"i\"])]\n",
    "dfY[\"base_path\"] = [f\"../data/images/{id}/000.png\" for id, i in zip(dfY[\"chain_id\"], dfY[\"i\"])]\n",
    "x_train, x_test, y_train, y_test = train_test_split(dfY[[\"path\", \"base_path\", \"range\"]], dfY[[\"x\", \"y\", \"z\", \"qw\",\"qx\",\"qy\",\"qz\"]], test_size=0.5, random_state=42)\n",
    "x_train = pd.DataFrame(x_train, columns=[\"path\", \"base_path\", \"range\"])\n",
    "print(x_train)\n",
    "x_test = pd.DataFrame(x_test, columns=[\"path\", \"base_path\", \"range\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "431fd5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_pos.save('../models/test_model-logcosh-c1x2-16x3-3e-000005-larger-kernels-7500-depth.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c49f034",
   "metadata": {},
   "outputs": [],
   "source": [
    "ToCSV = lambda df, fname: df.round(2).to_csv(f'{fname}.csv')\n",
    "\n",
    "# Loads all images found and trains given model\n",
    "def load_images_and_train_model(model, is_pos_model):\n",
    "    with tf.device('/GPU:0'):\n",
    "        model.summary()\n",
    "        \n",
    "        #for i in range(batches):\n",
    "            #batch = load_new_batch()\n",
    "            #model.fit([np.asarray(batch[0]), np.asarray(batch[1])], y_train[100 * i : 100*(i+1)], epochs=40, batch_size=batch_size_b)\n",
    "        if is_pos_model:\n",
    "            ypos = pd.DataFrame(y_train, index=y_train.index, columns=[\"x\", \"y\", \"z\"])\n",
    "            model.fit(CustomDataGenerator(x_train, y_train, batch_size=100), epochs=3)\n",
    "        else:\n",
    "            yquat = pd.DataFrame(y_train, index=y_train.index, columns=[\"qw\", \"qx\", \"qy\", \"qz\"])\n",
    "            model.fit(CustomDataGenerator(x_train, yquat, batch_size=100), epochs=3)\n",
    "\n",
    "\n",
    "        \n",
    "    #     ypreddf = pd.DataFrame(ypred.T, index=image_label_ds.take(count * 100 * 0.2).index_array, columns=[\"x\", \"y\", \"z\"])\n",
    "    #     dfY = pd.read_csv(\"../data/train_labels.csv\")[:count * 100]\n",
    "    #     dfY_merged = pd.merge(ypreddf.drop([\"x\", \"y\", \"z\"], axis=1), dfY, left_index=True, right_index=True)\n",
    "    #     dfYidx = dfY.drop([\"x\", \"y\", \"z\", \"qw\", \"qx\", \"qy\", \"qz\"], axis=1)\n",
    "    #     df_merged = pd.merge(ypreddf, dfYidx, left_index=True, right_index=True)\n",
    "    #     df_merged[\"qw\"] = 0\n",
    "    #     df_merged[\"qx\"] = 0\n",
    "    #     df_merged[\"qy\"] = 0\n",
    "    #     df_merged[\"qz\"] = 0\n",
    "    #     df_merged.loc[df_merged[\"i\"] == 0, [\"x\", \"y\", \"z\", \"qw\", \"qx\", \"qy\", \"qz\"]] = [0,0,0,1,0,0,0]\n",
    "    #     df_merged.set_index([\"chain_id\", \"i\"], inplace=True)\n",
    "    #    # df_merged.drop([\"id\"], axis=1, inplace=True)\n",
    "    #     ToCSV(df_merged, \"cnn-test\")\n",
    "    #     ToCSV(dfY_merged, \"cnn-true\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# from https://github.com/1988kramer/camera-pose/blob/master/camera-pose.py \n",
    "def create_conv_branch(input_shape):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(96, kernel_size=(11,11),\n",
    "\t\t\t\t\t strides=4, padding='valid',\n",
    "\t\t\t\t\t activation='relu',\n",
    "\t\t\t\t\t input_shape=input_shape))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\tmodel.add(Conv2D(128, kernel_size=(7,7),\n",
    "\t\t\t\t\t strides=1, padding='same',\n",
    "\t\t\t\t\t activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(3,3), strides=1))\n",
    "\tmodel.add(Conv2D(256, kernel_size=(3,3),\n",
    "\t\t\t\t\t strides=1, padding='same',\n",
    "\t\t\t\t\t activation='relu'))\n",
    "\t# model.add(Conv2D(256, kernel_size=(3,3),\n",
    "\t# \t\t\t\t strides=1, padding='same',\n",
    "\t# \t\t\t\t activation='relu'))\n",
    "\t# model.add(Conv2D(128, kernel_size=(3,3),\n",
    "\t# \t\t\t\t strides=1, padding='same',\n",
    "\t# \t\t\t\t activation='relu'))\n",
    "\t# model.add(MaxPooling2D(pool_size=(3,3), strides=2))\n",
    "\t# model.add(Conv2D(256, kernel_size=(3,3),\n",
    "\t# \t\t\t\t strides=1, padding='same',\n",
    "\t# \t\t\t\t activation='relu'))\n",
    "\t# model.add(Conv2D(128, kernel_size=(3,3),\n",
    "\t# \t\t\t\t strides=1, padding='same',\n",
    "\t# \t\t\t\t activation='relu'))\n",
    "\treturn model\n",
    "\n",
    "def create_conv_branch_pos(input_shape):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(96, kernel_size=(11,11),\n",
    "\t\t\t\t\t strides=4, padding='valid',\n",
    "\t\t\t\t\t activation='relu',\n",
    "\t\t\t\t\t input_shape=input_shape))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\tmodel.add(Conv2D(128, kernel_size=(7,7),\n",
    "\t\t\t\t\t strides=1, padding='same',\n",
    "\t\t\t\t\t activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(3,3), strides=1))\n",
    "\tmodel.add(Conv2D(256, kernel_size=(5,5),\n",
    "\t\t\t\t\t strides=1, padding='same',\n",
    "\t\t\t\t\t activation='relu'))\n",
    "\tmodel.add(Conv2D(256, kernel_size=(3,3),\n",
    "\t\t\t\t\t strides=1, padding='same',\n",
    "\t\t\t\t\t activation='relu'))\n",
    "\tmodel.add(Conv2D(128, kernel_size=(3,3),\n",
    "\t\t\t\t\t strides=1, padding='same',\n",
    "\t\t\t\t\t activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(3,3), strides=2))\n",
    "\tmodel.add(Conv2D(256, kernel_size=(5,5),\n",
    "\t\t\t\t\t strides=1, padding='same',\n",
    "\t\t\t\t\t activation='relu'))\n",
    "\tmodel.add(Conv2D(128, kernel_size=(3,3),\n",
    "\t\t\t\t\t strides=1, padding='same',\n",
    "\t\t\t\t\t activation='relu'))\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98b8fff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/63827339/how-to-build-a-custom-data-generator-for-keras-tf-keras-where-x-images-are-being\n",
    "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
    "\n",
    "    ''' Custom DataGenerator to load img \n",
    "    \n",
    "    Arguments:\n",
    "        data_frame = pandas data frame in filenames and labels format\n",
    "        batch_size = divide data in batches\n",
    "        shuffle = shuffle data before loading\n",
    "        img_shape = image shape in (h, w, d) format\n",
    "        augmentation = data augmentation to make model rebust to overfitting\n",
    "    \n",
    "    Output:\n",
    "        Img: numpy array of image\n",
    "        label : output label for image\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, data_frame, labels, batch_size=10, img_shape=None, augmentation=True, num_classes=None):\n",
    "        self.data_frame = data_frame\n",
    "        self.labels = labels\n",
    "        self.train_len = len(data_frame)\n",
    "        self.batch_size = batch_size\n",
    "        self.img_shape = img_shape\n",
    "        self.num_classes = num_classes\n",
    "        print(f\"Found {self.data_frame.shape[0]} images belonging to {self.num_classes} classes\")\n",
    "\n",
    "    def __len__(self):\n",
    "        ''' return total number of batches '''\n",
    "        #self.data_frame = shuffle(self.data_frame)\n",
    "        return math.ceil(self.train_len/self.batch_size)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        ''' shuffle data after every epoch '''\n",
    "        # fix on epoch end it's not working, adding shuffle in len for alternative\n",
    "        pass\n",
    "    \n",
    "    def __data_augmentation(self, img):\n",
    "        ''' function for apply some data augmentation '''\n",
    "        img = tf.image.resize(img, 512, 640)\n",
    "        img = tf.image.random_flip_up_down(img)\n",
    "        return img\n",
    "        \n",
    "    def __get_image(self, file_id):\n",
    "        \"\"\" open image with file_id path and apply data augmentation \"\"\"\n",
    "        img = np.asarray(Image.open(file_id))\n",
    "        img = np.resize(img, self.img_shape)\n",
    "        img = self.__data_augmentation(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def __get_label(self, label_id):\n",
    "        \"\"\" uncomment the below line to convert label into categorical format \"\"\"\n",
    "        #label_id = tf.keras.utils.to_categorical(label_id, num_classes)\n",
    "        return label_id\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # batch_x = self.data_frame[\"filenames\"][idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        # batch_y = self.data_frame[\"labels\"][idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        # # read your data here using the batch lists, batch_x and batch_y\n",
    "        # x = [self.__get_image(file_id) for file_id in batch_x] \n",
    "        # y = [self.__get_label(label_id) for label_id in batch_y]\n",
    "\n",
    "        y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        paths = self.data_frame[\"path\"][idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        base_paths = self.data_frame[\"base_path\"][idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        #raw = [tf.io.read_file(path) for path in paths]\n",
    "        image = [tf.image.resize(tf.image.decode_png(tf.io.read_file(path), channels=3), (512,640)) for path in paths]\n",
    "        #base_raw = tf.io.read_file(base_path)\n",
    "        base_image = [tf.image.resize(tf.image.decode_png(tf.io.read_file(path), channels=3), (512,640)) for path in base_paths]\n",
    "\n",
    "        # return [np.asarray(base_image), np.asarray(image), np.asarray(self.data_frame[idx * self.batch_size:(idx + 1) * self.batch_size][\"range\"])], y\n",
    "        return [np.asarray(base_image), np.asarray(image), np.asarray(self.data_frame[idx * self.batch_size:(idx + 1) * self.batch_size][\"range\"])], y\n",
    "\n",
    "        #return tf.convert_to_tensor(x), tf.convert_to_tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f054cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeQuat(x: tf.Tensor):\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(x)))\n",
    "    x = x / norm\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fae3acaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 22:58:31.568224: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 22:58:31.663714: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 22:58:31.664095: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 22:58:31.666677: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 22:58:31.667077: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 22:58:31.667337: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 22:58:31.909146: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 22:58:31.909651: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 22:58:31.909671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-29 22:58:31.910160: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 22:58:31.910194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9702 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 512, 640, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 512, 640, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " sequential (Sequential)     (None, 30, 38, 128)          2341760   ['input_1[0][0]',             \n",
      "                                                                     'input_2[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 30, 38, 256)          0         ['sequential[0][0]',          \n",
      "                                                                     'sequential[1][0]']          \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 291840)               0         ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 291841)               0         ['flatten[0][0]',             \n",
      " )                                                                   'input_3[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 291841)               0         ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 16)                   4669472   ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 16)                   0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 16)                   272       ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 16)                   0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 16)                   272       ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 7)                    119       ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7011895 (26.75 MB)\n",
      "Trainable params: 7011895 (26.75 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 512, 640, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 512, 640, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " sequential (Sequential)     (None, 30, 38, 128)          2341760   ['input_1[0][0]',             \n",
      "                                                                     'input_2[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 30, 38, 256)          0         ['sequential[0][0]',          \n",
      "                                                                     'sequential[1][0]']          \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 291840)               0         ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 291841)               0         ['flatten[0][0]',             \n",
      " )                                                                   'input_3[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 291841)               0         ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 16)                   4669472   ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 16)                   0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 16)                   272       ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 16)                   0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 16)                   272       ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 7)                    119       ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7011895 (26.75 MB)\n",
      "Trainable params: 7011895 (26.75 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Found 2500 images belonging to None classes\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 22:58:50.379673: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-04-29 22:58:50.640511: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-29 22:58:51.081705: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.71GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-04-29 22:58:54.721407: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.71GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-04-29 22:59:12.701332: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-29 22:59:13.376352: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f34ac505300 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-29 22:59:13.376407: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2024-04-29 22:59:13.384070: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1714449553.466084   19053 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-04-29 22:59:14.118157: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.87GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-04-29 22:59:14.405981: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-04-29 22:59:14.463969: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.87GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-04-29 22:59:14.749216: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-04-29 22:59:15.413434: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.00GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-04-29 22:59:16.040490: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.00GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-04-29 22:59:16.065079: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.65GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-04-29 22:59:16.239028: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.49GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 269s 9s/step - loss: 61.7006\n",
      "Epoch 2/3\n",
      "25/25 [==============================] - 215s 9s/step - loss: 61.3034\n",
      "Epoch 3/3\n",
      "25/25 [==============================] - 213s 9s/step - loss: 61.2684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x7f34e8307ca0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_shape=(512, 640, 3)\n",
    "\n",
    "# Rotation model\n",
    "# conv_branch = create_conv_branch(input_shape)\n",
    "# branch_a = Input(shape=input_shape)\n",
    "# branch_b = Input(shape=input_shape)\n",
    "\n",
    "# processed_a = conv_branch(branch_a)\n",
    "# processed_b = conv_branch(branch_b)\n",
    "\n",
    "# concat = keras.layers.concatenate([processed_a, processed_b])\n",
    "# c1 = Conv2D(256, kernel_size=(7,7),\n",
    "# \t\t\t\t\t strides=1, padding='same',\n",
    "# \t\t\t\t\t activation='relu')(concat)\n",
    "# c1 = Conv2D(128, kernel_size=(3,3),\n",
    "# \t\t\t\t\t strides=1, padding='same',\n",
    "# \t\t\t\t\t activation='relu')(c1)\n",
    "# c1 = GlobalAveragePooling2D()(c1)\n",
    "# x1 = Flatten()(c1)\n",
    "# x1 = Dropout(0.25)(x1)\n",
    "# x1 = Dense(8)(x1)\n",
    "# x1 = Dropout(0.25)(x1)\n",
    "# output = Dense(4)(x1)\n",
    "# postprocess = Lambda(NormalizeQuat, output_shape=(None,4))(output)\n",
    "\n",
    "# model_rot = Model(inputs=[branch_a,branch_b], outputs=postprocess)\n",
    "# model_rot.compile(optimizer=Adam(learning_rate=0.001), loss=\"log_cosh\")\n",
    "# model_rot.summary()\n",
    "# load_images_and_train_model(model_rot, False)\n",
    "\n",
    "# Position model\n",
    "conv_branch = create_conv_branch_pos(input_shape)\n",
    "branch_a = Input(shape=input_shape)\n",
    "branch_b = Input(shape=input_shape)\n",
    "\n",
    "processed_a = conv_branch(branch_a)\n",
    "processed_b = conv_branch(branch_b)\n",
    "\n",
    "concat = keras.layers.concatenate([processed_a, processed_b])\n",
    "c1 = Conv2D(256, kernel_size=(7,7),\n",
    "\t\t\t\t\t strides=1, padding='same',\n",
    "\t\t\t\t\t activation='relu')(concat)\n",
    "c1 = Conv2D(128, kernel_size=(3,3),\n",
    "\t\t\t\t\t strides=1, padding='same',\n",
    "\t\t\t\t\t activation='relu')(c1)\n",
    "# c1 = Conv2D(64, kernel_size=(3,3),\n",
    "# \t\t\t\t\t strides=1, padding='same',\n",
    "# \t\t\t\t\t activation='relu')(c1)\n",
    "c1 = MaxPooling2D(pool_size=(2,2))(c1)\n",
    "x1 = Flatten()(concat)\n",
    "r1 = Input(shape=1)\n",
    "concat2 = keras.layers.concatenate([x1,r1])\n",
    "x1 = Dropout(0.25)(concat2)\n",
    "x1 = Dense(16)(x1)\n",
    "x1 = Dropout(0.25)(x1)\n",
    "x1 = Dense(16)(x1)\n",
    "x1 = Dropout(0.25)(x1)\n",
    "x1 = Dense(16)(x1)\n",
    "output = Dense(7)(x1)\n",
    "\n",
    "model_pos = Model(inputs=[branch_a,branch_b,r1], outputs=output)\n",
    "model_pos.compile(optimizer=Adam(learning_rate=0.00005), loss=\"log_cosh\")\n",
    "model_pos.summary()\n",
    "load_images_and_train_model(model_pos, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30d89ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_pos = keras.models.load_model('../models/test_model-logcosh-16x3-3e-00001-larger-kernels.keras')\n",
    "#model_pos = keras.models.load_model('../models/test_model-logcosh-c1x2-16x3-3e-000005-larger-kernels-7500-depth.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38166d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2500 images belonging to None classes\n",
      "50/50 [==============================] - 221s 4s/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "#ypred = pd.DataFrame(model_rot.predict(CustomDataGenerator(x_test, y_test, 20)), index=y_test.index, columns=[\"qw\", \"qx\", \"qy\", \"qz\"]) # Predict rotation\n",
    "ypred = pd.DataFrame(model_pos.predict(CustomDataGenerator(x_test, y_test, 50)), index=y_test.index, columns=[\"x\", \"y\", \"z\", \"qw\", \"qx\", \"qy\", \"qz\"]) # Predict position\n",
    "#ypred = pd.merge(ypred_pos, ypred_rot, left_index=True, right_index=True)\n",
    "#ypred[[\"qw\", \"qx\", \"qy\", \"qz\"]] = ypred[[\"qw\", \"qx\", \"qy\", \"qz\"]].clip(lower=-1, upper=1)\n",
    "\n",
    "ypred[\"chain_id\"] = dfY.loc[ypred.index].chain_id\n",
    "ypred[\"i\"] = dfY.loc[ypred.index].i.astype(int)\n",
    "ypred.set_index([\"chain_id\", \"i\"], inplace=True)\n",
    "y_pred_norm = np.linalg.norm(ypred[[\"qw\", \"qx\", \"qy\", \"qz\"]], axis=1)\n",
    "ypred[\"qw\"] = ypred[\"qw\"] / y_pred_norm\n",
    "ypred[\"qx\"] = ypred[\"qx\"] / y_pred_norm\n",
    "ypred[\"qy\"] = ypred[\"qy\"] / y_pred_norm\n",
    "ypred[\"qz\"] = ypred[\"qz\"] / y_pred_norm\n",
    "#ypred.loc[ypred.i == 0, [\"x\", \"y\", \"z\", \"qw\", \"qx\", \"qy\", \"qz\"]] = [0,0,0,1,0,0,0]\n",
    "# ypred[[\"qw\", \"qx\", \"qy\", \"qz\"]] = [0,0,0,0]\n",
    "#ypred[[\"x\", \"y\", \"z\"]] = [0,0,0]\n",
    "#ypred = ypred[[\"chain_id\", \"i\", \"x\", \"y\", \"z\", \"qw\", \"qx\", \"qy\", \"qz\"]]\n",
    "#ypred.loc[ypred.i == 0, [\"x\", \"y\", \"z\", \"qw\", \"qx\", \"qy\", \"qz\"]] = [0,0,0,1,0,0,0]\n",
    "ypred.loc[(slice(None), 0), [\"x\", \"y\", \"z\", \"qw\", \"qx\", \"qy\", \"qz\"]] = [0,0,0,1,0,0,0]\n",
    "#ypred.set_index([\"chain_id\", \"i\"], inplace=True)\n",
    "ToCSV(ypred, \"cnn-test\")\n",
    "y_copy = y_test.copy()\n",
    "y_copy[\"chain_id\"] = dfY.loc[y_copy.index].chain_id\n",
    "y_copy[\"i\"] = dfY.loc[y_copy.index].i.astype(int)\n",
    "y_copy.set_index([\"chain_id\", \"i\"], inplace=True)\n",
    "ToCSV(y_copy, \"cnn-true\")\n",
    "\n",
    "#model.save('../models/test_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
