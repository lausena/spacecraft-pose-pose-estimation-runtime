{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95276a61-386d-4ebb-9ce4-f64a5e070b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lausena/developer/repos/spacecraft-pose-pose-estimation-runtime/juptyer-notebooks\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db1aad66-1ae3-4fff-b703-b5312023d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transforms3d --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4b25795b-5f49-4e90-aa8a-3cb69b3bd5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import transforms3d.quaternions as quat\n",
    "from scipy import signal\n",
    "import scipy.fft as sfft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "98ca6485-6b16-4a0e-8f39-2d5522d8bd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_length_x = 5212.5371\n",
    "focal_length_y = 6255.0444\n",
    "principal_point_x = 640.\n",
    "principal_point_y = 512.\n",
    "K = np.array([[focal_length_x, 0, principal_point_x],\n",
    "                          [0, focal_length_y,principal_point_y],\n",
    "                          [0, 0, 1]])\n",
    "K\n",
    "\n",
    "# range 01f0f7459b,0,299.2\n",
    "#01f0f7459b,1,\n",
    "\n",
    "laser_range_distance = 300\n",
    "\n",
    "labels = np.array([[7.64022827,-46.98920059,-42.21747971,0.98997474,-0.0941886,-0.07856753,0.07003857],\n",
    "    [12.37142944,-36.08272934,-76.19368744,0.98547542,-0.09323603,-0.13402745,0.04670797],\n",
    "    [48.83045959,-62.45590591,-149.01345825,0.9463315,-0.15760925,-0.27446723,0.06544811],\n",
    "    [42.9213562,3.1468811,-156.43341064,0.96294099,-0.05801675,-0.26296937,-0.0150205],\n",
    "    [25.3291626,-15.59156799,-118.26628113,0.97709697,-0.05717814,-0.20439324,0.01534067],\n",
    "    [55.51976013,-30.00940132,-172.91856384,0.94631386,-0.10770535,-0.30420068,0.01874543],\n",
    "    [ 69.65390015,-14.23764992,-194.42814636,0.93474096,-0.0921587,-0.34309945,-0.00697307],\n",
    "    [67.03590393,57.95062637,-181.86766052,0.94076264,0.03300816,-0.32461578,-0.09219801],\n",
    "    [95.08578491,70.74472046,-209.08718872,0.91551983,0.02235752,-0.38302255,-0.12090118],\n",
    "    [115.60142517,80.90587616,-223.3885498,0.89717531,0.01968047,-0.41800421,-0.14128494]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8214af42-fbe0-4b14-a782-5b01b5ce8f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/lausena/developer/repos/spacecraft-pose-pose-estimation-runtime/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "97723957-4150-4db7-a8e1-25e030940a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image 001:\n",
    "# trans 7.64022827,-46.98920059,-42.21747971\n",
    "# quat ,0.98997474,-0.0941886,-0.07856753,0.07003857\n",
    "orig_trans = np.array([7.64022827,-46.98920059,-42.21747971])\n",
    "orig_quat = np.array([0.98997474,-0.0941886,-0.07856753,0.07003857])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "bc971885-b833-42f1-9262-e47786d605e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1path = os.path.join(root, 'data/images/01f0f7459b/000.png')\n",
    "img2path = os.path.join(root, 'data/images/01f0f7459b/001.png')\n",
    "\n",
    "img1 = cv2.imread(img1path, cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread(img2path, cv2.IMREAD_GRAYSCALE)\n",
    "img1full = cv2.imread(img1path, cv2.IMREAD_GRAYSCALE)\n",
    "img2full = cv2.imread(img2path, cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4e802c61-619e-46cd-88a9-f889394de09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "orb = cv2.ORB_create()\n",
    "kp1, des1 = orb.detectAndCompute(img2, None)\n",
    "kp2, des2 = orb.detectAndCompute(img1, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f6802e92-c903-4865-9f91-0f714a56e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = bf.match(des1, des2)\n",
    "\n",
    "matched_keypoints1 = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "matched_keypoints2 = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1bc225c1-80a3-4650-a99a-bbee61b05a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_matrix, _ = cv2.findEssentialMat(matched_keypoints1, matched_keypoints2, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "65602e1a-c982-45f3-acb7-e244a339767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, R, t, _ = cv2.recoverPose(essential_matrix, matched_keypoints1, matched_keypoints2, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a19d1dfa-042d-48a7-ace1-916ef88e08b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert rotation vector to rotation matrix\n",
    "R_mat, _ = cv2.Rodrigues(R)\n",
    "\n",
    "# Compute translation\n",
    "translation = -np.dot(R_mat.T, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "5125948f-7dae-4753-8d6e-d1b851b8ad96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.882302856666666"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean_squared_error(-R_mat.ravel() * t.T, orig_trans)\n",
    "res = -R_mat.ravel() * t.T\n",
    "res[0]\n",
    "mean_absolute_error(res[0], orig_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "85d1d252-fb7b-44e5-81f4-0caf289e30b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1210821 , -0.20337419,  0.97158534])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x,y,z (i.e., forward-backward, left-right, up-down)\n",
    "t.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a6d2e760-12f6-4f65-969d-de7ebfcfcc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factor = laser_range_distance/t[2]\n",
    "translation_scaled = t*scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5a9dbfb4-135c-43a6-8f0a-2cce265c8052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7.64022827 -46.98920059 -42.21747971]\n",
      "[ 0.1210821  -0.20337419  0.97158534]\n",
      "[ 37.3869667 -62.7966004 300.       ]\n"
     ]
    }
   ],
   "source": [
    "print(orig_trans)\n",
    "print(t.ravel())\n",
    "print(translation_scaled.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "65d12951-279e-41d5-a498-5dd115bc7366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1349.5578843897417\n",
      "1370.248816996463\n",
      "39415.848585019805\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(np.array([0.,0.,0.]), orig_trans))\n",
    "print(mean_squared_error(t.ravel(), orig_trans))\n",
    "print(mean_squared_error(translation_scaled.ravel(), orig_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6faedda-7b74-4993-b1f5-7a1ccfe1b788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5270817984556209 : recover pose\n"
     ]
    }
   ],
   "source": [
    "a = Rotation.from_matrix(R).as_quat()\n",
    "a\n",
    "# print('Quaternion test:')\n",
    "print(f'{mean_absolute_error(a, orig_quat)} : recover pose')\n",
    "# print(mean_absolute_error(b, orig_quat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f655321-50a4-4f55-acff-ac5f7f40496c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec9dc4a-def3-4992-8287-80a9f4f03c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "1beac01a-8e3c-47fb-9685-7dbf145cd73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7.64022827 -46.98920059 -42.21747971]\n",
      "[ 222.12278313 -208.33042203    0.        ]\n",
      "[ 111.06139156 -104.16521102  988.33950448]\n",
      "32.28230285666667 = BASE CASE\n",
      "139.34708533674873\n",
      "\n",
      "[ 12.37142944 -36.08272934 -76.19368744]\n",
      "[ 5.36144895 -1.47600951  0.        ]\n",
      "[ 2.68072447e+00 -7.38004753e-01 -9.99996135e+02]\n",
      "41.54928207333334 = BASE CASE\n",
      "39.27012925529106\n",
      "\n",
      "[  48.83045959  -62.45590591 -149.01345825]\n",
      "[-1.87499077  9.45718234  0.        ]\n",
      "[-9.37495386e-01  4.72859117e+00 -9.99988381e+02]\n",
      "86.76660791666666 = BASE CASE\n",
      "90.5439989544373\n",
      "\n",
      "[  42.9213562     3.1468811  -156.43341064]\n",
      "[-35.21345148  38.12748642   0.        ]\n",
      "[-17.60672574  19.06374321 999.66323175]\n",
      "67.50054931333334 = BASE CASE\n",
      "89.84960787917969\n",
      "\n",
      "[  25.3291626   -15.59156799 -118.26628113]\n",
      "[ 13.19774527 -23.6587227    0.        ]\n",
      "[  6.59887264 -11.82936135 999.90825634]\n",
      "53.06233724 = BASE CASE\n",
      "46.15495105498322\n",
      "\n",
      "[  55.51976013  -30.00940132 -172.91856384]\n",
      "[11.90943051 -9.00367343  0.        ]\n",
      "[  5.95471526  -4.50183671 999.97213703]\n",
      "86.14924176333334 = BASE CASE\n",
      "79.1782071166856\n",
      "\n",
      "[  69.65390015  -14.23764992 -194.42814636]\n",
      "[-32.72847164 -11.21229866   0.        ]\n",
      "[-16.36423582  -5.60614933 999.85038024]\n",
      "92.77323214333335 = BASE CASE\n",
      "99.94528980200802\n",
      "\n",
      "[  67.03590393   57.95062637 -181.86766052]\n",
      "[-7.94624218  9.56956291  0.        ]\n",
      "[ -3.97312109   4.78478145 999.9806599 ]\n",
      "102.28473027333332 = BASE CASE\n",
      "101.74362336329663\n",
      "\n",
      "[  95.08578491   70.74472046 -209.08718872]\n",
      "[-10.96868468  16.39586785   0.        ]\n",
      "[ -5.48434234   8.19793393 999.95135675]\n",
      "124.97256469666667 = BASE CASE\n",
      "123.16350363848797\n",
      "\n",
      "Frac of best : 0.6\n"
     ]
    }
   ],
   "source": [
    "start = 1\n",
    "N = 10\n",
    "n_beat_base = 1\n",
    "for i in range(start, N):\n",
    "    # 06d74ed510/\n",
    "    # 01f0f7459b\n",
    "    chaindir = \"06d74ed510\"\n",
    "    img1path = os.path.join(root, f'data/images/{chaindir}/000.png')\n",
    "    img2path = os.path.join(root, f'data/images/01f0f7459b/00{i}.png')\n",
    "    \n",
    "    img1 = cv2.imread(img1path, cv2.IMREAD_GRAYSCALE)\n",
    "    img2 = cv2.imread(img2path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    try:\n",
    "        orb = cv2.ORB_create()\n",
    "        keypoints1, descriptors1 = orb.detectAndCompute(img1, None)\n",
    "        keypoints2, descriptors2 = orb.detectAndCompute(img2, None)\n",
    "    \n",
    "        # Match keypoints between the two images\n",
    "        matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "        matches = matcher.match(descriptors1, descriptors2, None)\n",
    "        \n",
    "        # Extract matched keypoints\n",
    "        points1 = np.float32([keypoints1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        points2 = np.float32([keypoints2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        \n",
    "        # Compute Fundamental matrix (F) and Essential matrix (E)\n",
    "        F, mask = cv2.findFundamentalMat(points1, points2, cv2.RANSAC)\n",
    "        E, mask = cv2.findEssentialMat(points1, points2, K)\n",
    "        \n",
    "        # Decompose Essential matrix to get rotation and translation\n",
    "        _, R, t, _ = cv2.recoverPose(E, points1, points2, K)\n",
    "        \n",
    "        # zero out the z and scale by 2k\n",
    "        ttmp = np.append(t[:2], 0) * 2000\n",
    "        \n",
    "        original_trans = labels[i-1][:3]\n",
    "        original_quat = labels[i-1][3:]\n",
    "\n",
    "        print(original_trans)\n",
    "        print(ttmp)\n",
    "        print(t.ravel() * 1000)\n",
    "    \n",
    "        base_result = mean_absolute_error(np.array([0,0,0]),original_trans)\n",
    "        test_result = mean_absolute_error(ttmp,original_trans)\n",
    "        if test_result < base_result:\n",
    "            n_beat_base += 1\n",
    "        print(f'{base_result} = BASE CASE')\n",
    "        print(test_result)\n",
    "        print()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "print(f'Frac of best : {n_beat_base / N}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "55b688a6-dcc8-4d9c-9d35-4c240a9068a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=np.array([2,3,4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "5baff16f-2012-4f39-892b-30833145eefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "p[2]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "cdc90a1c-3e69-495a-80ed-fdbd10321604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 2])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da763f0b-c18f-4c46-acdd-31dfda1970d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9488993c-faa5-4035-8f7d-35c343c7b6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e40846d-ccfb-40b7-82f2-77e94671697a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3959af36-ab1b-41ec-ad29-cac9c0f29297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be80f775-1873-42aa-9c1f-a3577992c978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f677297-3dd1-4c64-b508-c2bacc784b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d79e258-2fc1-4c7f-b66e-b528e5031f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec5ee28-7010-42dd-ac0a-17b680336cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "772636ae-7117-403c-91f1-f7f419effea7",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) /home/conda/feedstock_root/build_artifacts/libopencv_1704864625327/work/modules/calib3d/src/triangulate.cpp:82: error: (-209:Sizes of input arguments do not match) Size of projection matrices must be 3x4 in function 'icvTriangulatePoints'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m dst_pts \u001b[38;5;241m=\u001b[39m dst_pts[mask\u001b[38;5;241m.\u001b[39mravel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Triangulate points using the camera intrinsic matrix\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m pts4D \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtriangulatePoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcamera_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_pts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_pts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Convert homogeneous coordinates to Cartesian\u001b[39;00m\n\u001b[1;32m     40\u001b[0m pts3D \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mconvertPointsFromHomogeneous(pts4D\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /home/conda/feedstock_root/build_artifacts/libopencv_1704864625327/work/modules/calib3d/src/triangulate.cpp:82: error: (-209:Sizes of input arguments do not match) Size of projection matrices must be 3x4 in function 'icvTriangulatePoints'\n"
     ]
    }
   ],
   "source": [
    "img1path = os.path.join(root, 'data/images/01f0f7459b/000.png')\n",
    "img2path = os.path.join(root, f'data/images/01f0f7459b/001.png')\n",
    "\n",
    "img1 = cv2.imread(img1path, cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread(img2path, cv2.IMREAD_GRAYSCALE)\n",
    "img1full = cv2.imread(img1path, cv2.IMREAD_GRAYSCALE)\n",
    "img2full = cv2.imread(img2path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "orb = cv2.ORB_create()\n",
    "kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "# Match keypoints\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = bf.match(des1, des2)\n",
    "# Extract matched keypoints\n",
    "src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "# Match descriptors\n",
    "matches = bf.match(des1, des2)\n",
    "\n",
    "# Sort them in the order of their distance\n",
    "matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "# Extract matched keypoints\n",
    "src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "# Calculate Fundamental matrix\n",
    "F, mask = cv2.findFundamentalMat(src_pts, dst_pts, cv2.FM_RANSAC)\n",
    "\n",
    "# Select only inlier points\n",
    "src_pts = src_pts[mask.ravel() == 1]\n",
    "dst_pts = dst_pts[mask.ravel() == 1]\n",
    "\n",
    "# Triangulate points using the camera intrinsic matrix\n",
    "pts4D = cv2.triangulatePoints(np.eye(3), camera_matrix, src_pts.T, dst_pts.T)\n",
    "\n",
    "# Convert homogeneous coordinates to Cartesian\n",
    "pts3D = cv2.convertPointsFromHomogeneous(pts4D.T.reshape(-1, 4))\n",
    "\n",
    "# Calculate translation vector in real-world coordinates\n",
    "translation_vector = np.mean(pts3D, axis=0)\n",
    "\n",
    "# Output translation vector\n",
    "print(\"Translation (x, y, z) in real-world units:\", translation_vector.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d64db779-0047-4d80-b0c8-b479da2ff25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_test(img1, img2, orig_trans, orig_quat):\n",
    "    orb = cv2.ORB_create()\n",
    "    kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "    kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "    # Match keypoints\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    # Extract matched keypoints\n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "    # Estimate homography\n",
    "    # H, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC)\n",
    "    H, _ = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC)\n",
    "\n",
    "    num, Rs, Ts, Ns = cv2.decomposeHomographyMat(H, camera_matrix)\n",
    "    a = Rotation.from_matrix(Rs[0]).as_quat()\n",
    "    b = Rotation.from_matrix(H).as_quat()\n",
    "\n",
    "    # print('Quaternion test:')\n",
    "    # print(f'{mean_absolute_error(a, orig_quat)} : Decomposition')\n",
    "    # print(mean_absolute_error(b, orig_quat))\n",
    "    # print()\n",
    "    print('Translation test:')\n",
    "    print(f'{mean_absolute_error(np.array([0.,0.,0.]), orig_trans)} Base case')\n",
    "    print(mean_absolute_error(Ts[0], orig_trans))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6c33e810-19c6-460a-8264-dc006efa1ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image = 1\n",
      "Translation test:\n",
      "32.28230285666667 Base case\n",
      "33.59082343862354\n",
      "\n",
      "Image = 2\n",
      "Translation test:\n",
      "41.54928207333334 Base case\n",
      "45.747369978317465\n",
      "\n",
      "Image = 3\n",
      "Translation test:\n",
      "86.76660791666666 Base case\n",
      "91.3611142404352\n",
      "\n",
      "Image = 4\n",
      "Translation test:\n",
      "67.50054931333334 Base case\n",
      "53.65835905079221\n",
      "\n",
      "Image = 5\n",
      "Translation test:\n",
      "53.06233724 Base case\n",
      "57.6353925224469\n",
      "\n",
      "Image = 6\n",
      "Translation test:\n",
      "86.14924176333334 Base case\n",
      "39.95098152651341\n",
      "\n",
      "Image = 7\n",
      "Translation test:\n",
      "92.77323214333335 Base case\n",
      "39.434431765392404\n",
      "\n",
      "Image = 8\n",
      "Translation test:\n",
      "102.28473027333332 Base case\n",
      "57.15854380839394\n",
      "\n",
      "Image = 9\n",
      "Translation test:\n",
      "124.97256469666667 Base case\n",
      "89.59045605843141\n",
      "\n",
      "Image = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@3188.895] global loadsave.cpp:248 findDecoder imread_('/home/lausena/developer/repos/spacecraft-pose-pose-estimation-runtime/data/images/01f0f7459b/0010.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@3188.922] global loadsave.cpp:248 findDecoder imread_('/home/lausena/developer/repos/spacecraft-pose-pose-estimation-runtime/data/images/01f0f7459b/0010.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) /home/conda/feedstock_root/build_artifacts/libopencv_1704864625327/work/modules/core/src/batch_distance.cpp:274: error: (-215:Assertion failed) type == src2.type() && src1.cols == src2.cols && (type == CV_32F || type == CV_8U) in function 'batchDistance'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[136], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m original_trans \u001b[38;5;241m=\u001b[39m labels[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][:\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m     23\u001b[0m original_quat \u001b[38;5;241m=\u001b[39m labels[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m3\u001b[39m:]\n\u001b[0;32m---> 25\u001b[0m \u001b[43mexecute_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_trans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_quat\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[135], line 7\u001b[0m, in \u001b[0;36mexecute_test\u001b[0;34m(img1, img2, orig_trans, orig_quat)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Match keypoints\u001b[39;00m\n\u001b[1;32m      6\u001b[0m bf \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mBFMatcher(cv2\u001b[38;5;241m.\u001b[39mNORM_HAMMING, crossCheck\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 7\u001b[0m matches \u001b[38;5;241m=\u001b[39m \u001b[43mbf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdes1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdes2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Extract matched keypoints\u001b[39;00m\n\u001b[1;32m      9\u001b[0m src_pts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32([kp1[m\u001b[38;5;241m.\u001b[39mqueryIdx]\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m matches])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /home/conda/feedstock_root/build_artifacts/libopencv_1704864625327/work/modules/core/src/batch_distance.cpp:274: error: (-215:Assertion failed) type == src2.type() && src1.cols == src2.cols && (type == CV_32F || type == CV_8U) in function 'batchDistance'\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    print(f'Image = {i}')\n",
    "    img1path = os.path.join(root, 'data/images/01f0f7459b/000.png')\n",
    "    img2path = os.path.join(root, f'data/images/01f0f7459b/00{i}.png')\n",
    "    \n",
    "    img1 = cv2.imread(img1path, cv2.IMREAD_GRAYSCALE)\n",
    "    img2 = cv2.imread(img2path, cv2.IMREAD_GRAYSCALE)\n",
    "    img1full = cv2.imread(img1path, cv2.IMREAD_GRAYSCALE)\n",
    "    img2full = cv2.imread(img2path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    original_trans = labels[i-1][:3]\n",
    "    original_quat = labels[i-1][3:]\n",
    "    \n",
    "    execute_test(img1, img2, original_trans, original_quat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1c54ee-b495-4626-a792-7ac05c6e994e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed794b03-bbaf-4718-bef7-9f1ea8eb2ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "98ea3b2c-5d2d-492d-a122-da6f8d36a219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_points(image_path):\n",
    "    # Read the image\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Initialize the ORB detector\n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = orb.detectAndCompute(gray, None)\n",
    "\n",
    "    # Convert keypoints to numpy array\n",
    "    img_points = np.float32([kp.pt for kp in keypoints])\n",
    "\n",
    "    return img_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c2fed3cb-8c25-4c02-b542-9af222978013",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) /home/conda/feedstock_root/build_artifacts/libopencv_1704864625327/work/modules/calib3d/src/five-point.cpp:446: error: (-215:Assertion failed) npoints >= 0 && points2.checkVector(2) == npoints && points1.type() == points2.type() in function 'findEssentialMat'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[182], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m img_points2_norm \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mundistortPoints(img_points2\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m), K, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Compute essential matrix\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m E, _ \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindEssentialMat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_points1_norm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_points2_norm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# E, _ = cv2.findEssentialMat(img_points1_norm, img_points2_norm, K)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Decompose essential matrix to get rotation and translation\u001b[39;00m\n\u001b[1;32m     18\u001b[0m _, R, t, _ \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mrecoverPose(E, img_points1_norm, img_points2_norm, K)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /home/conda/feedstock_root/build_artifacts/libopencv_1704864625327/work/modules/calib3d/src/five-point.cpp:446: error: (-215:Assertion failed) npoints >= 0 && points2.checkVector(2) == npoints && points1.type() == points2.type() in function 'findEssentialMat'\n"
     ]
    }
   ],
   "source": [
    "img1path = os.path.join(root, 'data/images/01f0f7459b/000.png')\n",
    "img2path = os.path.join(root, 'data/images/01f0f7459b/001.png')\n",
    "img1 = cv2.imread(img1path, cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread(img2path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "img_points1 = extract_image_points(img1path)\n",
    "img_points2 = extract_image_points(img2path)\n",
    "\n",
    "img_points1_norm = cv2.undistortPoints(img_points1.reshape(-1,1,2), K, None)\n",
    "img_points2_norm = cv2.undistortPoints(img_points2.reshape(-1,1,2), K, None)\n",
    "\n",
    "# Compute essential matrix\n",
    "E, _ = cv2.findEssentialMat(np.float32(img_points1_norm), np.float32(img_points2_norm), K)\n",
    "\n",
    "# E, _ = cv2.findEssentialMat(img_points1_norm, img_points2_norm, K)\n",
    "\n",
    "# Decompose essential matrix to get rotation and translation\n",
    "_, R, t, _ = cv2.recoverPose(E, img_points1_norm, img_points2_norm, K)\n",
    "\n",
    "# Convert rotation vector to rotation matrix\n",
    "R_mat, _ = cv2.Rodrigues(R)\n",
    "\n",
    "# Compute translation\n",
    "translation = -np.dot(R_mat.T, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c2eaabca-d6fd-4dfd-912f-2c090182f22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.50534107, -0.52868734,  0.        ])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cffa8f-ae23-4bc7-b6a4-f37afb3b71da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "10c26243-ceb7-47c2-a7b5-99e9a676878b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.75640526, -0.0809536 ,  3.25011009])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ts[0].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5eb096b0-4e79-4c4f-bec9-c7d5c8009a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.64022827, -46.98920059, -42.21747971])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced8646-2106-4d4d-8e19-10ca655ab989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa338de5-b38e-43f2-bc60-8d25b70cb85e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad6ca53-8131-4ab1-80fd-425adcbe4eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c9171c-78d3-48a0-85b1-ba8908d1d01c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9d8b4c-0b9e-48bd-9287-4a5c89bc448b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f77a5c-304a-4cb3-99f0-5fd24b65b644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fed9b07-5736-4190-8ec4-d5ee7cb61867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4977d283-f071-4b62-bf44-f7a740a57e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6b885852-96f8-4216-84d7-fe1f889dc4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints1, descriptor1 = sift.detectAndCompute(img1, None)\n",
    "keypoints2, descriptor2 = sift.detectAndCompute(img2, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "868852a8-e5e1-43de-a6c7-fb2c5833d433",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLANN_INDEX_KDTREE = 1\n",
    "indexParams = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "searchParams = dict(checks=50)\n",
    "flann = cv.FlannBasedMatcher(indexParams, searchParams)\n",
    "nNeighbors = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "03a56fcb-9ae9-402a-ac62-c321e5a636f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = flann.knnMatch(descriptor1, descriptor2, k=nNeighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9c9838db-6474-4aa4-84fe-f3872303dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "goodMatches = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.7*n.distance:\n",
    "        goodMatches.append(m)\n",
    "\n",
    "minGoodMatches = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "228465f3-f058-4a84-821b-27e0fd8f9f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(goodMatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2fb7f795-df62-40c5-88ff-d166d6b5a432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough good matches\n"
     ]
    }
   ],
   "source": [
    "if len(goodMatches) > minGoodMatches:\n",
    "    source_points = np.float32([keypoints1[m.queryIdx].pt for m in goodMatches]).reshape(-1,1,2)\n",
    "    destination_points = np.float32([keypoints2[m.queryIdx].pt for m in goodMatches]).reshape(-1,1,2)\n",
    "    errorThreshold = 5\n",
    "    M, mask = cv.findHomography(source_points, destination_points, cv.RANSAC, errorThreshold)\n",
    "    matches_mask = mask.ravel().tolist()\n",
    "    h,w = img1.shape\n",
    "    img_border = np.float32([[0,0], [0, h-1], [w-1, h-1], [w-1,0]]).reshape(-1,1,2)\n",
    "    warped_img_border = cv.perspectiveTransform(img_border, M)\n",
    "    img2_poly = cv.polylines(img2, [np.int32(warped_img_border)], True, 255, 3, cv.LINE_AA)\n",
    "else:\n",
    "    print('Not enough good matches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2dbaeced-ca99-40a5-b3c4-58c528ac3737",
   "metadata": {},
   "outputs": [],
   "source": [
    "num, Rs, Ts, Ns = cv2.decomposeHomographyMat(M, camera_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f66267eb-b6a0-4043-ab2d-23ceb12a9f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Rotation.from_matrix(Rs[0]).as_quat()\n",
    "b = Rotation.from_matrix(H).as_quat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "31e7de2d-2979-44bb-8b2a-840266a3cf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5360092775186155\n",
      "0.30566994567587386\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(a, orig_quat))\n",
    "print(mean_absolute_error(b, orig_quat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8900a0d2-6ecc-47d5-a5f8-b9b640a441b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.28230285666667\n",
      "1088.50286222482\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(np.array([0.,0.,0.]), orig_trans))\n",
    "print(mean_absolute_error(Ts[0], orig_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98491c65-91f1-44bc-b121-d1138d666060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cf3007-3dd9-471a-a427-de4ddf7d0d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
